{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (2.1.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.22.2-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.9.18-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.1-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting click>=8.0.1 (from wandb)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from wandb) (4.4.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.42.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3->wandb)\n",
      "  Downloading pydantic_core-2.41.4-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\desktop\\y4s1\\sc3000\\lab assignment 1\\nanogpt-math\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/879.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/879.1 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.1/879.1 kB 2.2 MB/s  0:00:00\n",
      "Using cached wandb-0.22.2-py3-none-win_amd64.whl (19.1 MB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.6 MB/s  0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading aiohttp-3.13.1-cp313-cp313-win_amd64.whl (450 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Using cached pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "Using cached regex-2025.9.18-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached sentry_sdk-2.42.0-py2.py3-none-any.whl (379 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading pandas-2.3.3-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/11.0 MB 2.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/11.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.0 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/11.0 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.8/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.7/11.0 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.7 MB/s  0:00:04\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, typing-extensions, smmap, sentry-sdk, safetensors, regex, pyarrow, protobuf, propcache, multidict, frozenlist, dill, click, annotated-types, aiohappyeyeballs, yarl, typing-inspection, tiktoken, pydantic-core, pandas, multiprocess, huggingface-hub, gitdb, aiosignal, tokenizers, pydantic, gitpython, aiohttp, wandb, transformers, datasets\n",
      "\n",
      "   ----------------------------------------  0/33 [pytz]\n",
      "   ----------------------------------------  0/33 [pytz]\n",
      "   - --------------------------------------  1/33 [xxhash]\n",
      "   -- -------------------------------------  2/33 [tzdata]\n",
      "   -- -------------------------------------  2/33 [tzdata]\n",
      "  Attempting uninstall: typing-extensions\n",
      "   -- -------------------------------------  2/33 [tzdata]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   -- -------------------------------------  2/33 [tzdata]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   -- -------------------------------------  2/33 [tzdata]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   --- ------------------------------------  3/33 [typing-extensions]\n",
      "   ---- -----------------------------------  4/33 [smmap]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------ ---------------------------------  5/33 [sentry-sdk]\n",
      "   ------- --------------------------------  6/33 [safetensors]\n",
      "   -------- -------------------------------  7/33 [regex]\n",
      "   -------- -------------------------------  7/33 [regex]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   --------- ------------------------------  8/33 [pyarrow]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ---------- -----------------------------  9/33 [protobuf]\n",
      "   ------------ --------------------------- 10/33 [propcache]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   --------------- ------------------------ 13/33 [dill]\n",
      "   ---------------- ----------------------- 14/33 [click]\n",
      "   ---------------- ----------------------- 14/33 [click]\n",
      "   ---------------- ----------------------- 14/33 [click]\n",
      "   ------------------- -------------------- 16/33 [aiohappyeyeballs]\n",
      "   -------------------- ------------------- 17/33 [yarl]\n",
      "   ----------------------- ---------------- 19/33 [tiktoken]\n",
      "   ------------------------ --------------- 20/33 [pydantic-core]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   ------------------------- -------------- 21/33 [pandas]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   -------------------------- ------------- 22/33 [multiprocess]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   --------------------------- ------------ 23/33 [huggingface-hub]\n",
      "   ----------------------------- ---------- 24/33 [gitdb]\n",
      "   ----------------------------- ---------- 24/33 [gitdb]\n",
      "   ----------------------------- ---------- 24/33 [gitdb]\n",
      "   ------------------------------- -------- 26/33 [tokenizers]\n",
      "   ------------------------------- -------- 26/33 [tokenizers]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   -------------------------------- ------- 27/33 [pydantic]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   --------------------------------- ------ 28/33 [gitpython]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ----------------------------------- ---- 29/33 [aiohttp]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------ --- 30/33 [wandb]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   ------------------------------------- -- 31/33 [transformers]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   -------------------------------------- - 32/33 [datasets]\n",
      "   ---------------------------------------- 33/33 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 annotated-types-0.7.0 click-8.3.0 datasets-4.2.0 dill-0.4.0 frozenlist-1.8.0 gitdb-4.0.12 gitpython-3.1.45 huggingface-hub-0.35.3 multidict-6.7.0 multiprocess-0.70.16 pandas-2.3.3 propcache-0.4.1 protobuf-6.33.0 pyarrow-21.0.0 pydantic-2.12.3 pydantic-core-2.41.4 pytz-2025.2 regex-2025.9.18 safetensors-0.6.2 sentry-sdk-2.42.0 smmap-5.0.2 tiktoken-0.12.0 tokenizers-0.22.1 transformers-4.57.1 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 wandb-0.22.2 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install torch numpy transformers datasets tiktoken wandb tqdm\n",
    "\n",
    "# Used virtual environment, use above if you want to run on local\n",
    "%pip install matplotlib\n",
    "%pip install torch numpy transformers datasets tiktoken wandb tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "beta = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "max_length = 256\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "\n",
    "UNK_ID = 0 # pad is 0 and is ignored in less\n",
    "FALLBACK_ID = stoi.get('.', stoi.get(' ', UNK_ID))\n",
    "\n",
    "def encode(s): return [stoi.get(c, FALLBACK_ID) for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_texts = [(b.get(\"hard_negative\") or b[\"negative\"]) for b in batch]\n",
    "        pos_texts = [b[\"positive\"] for b in batch]\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()\n",
    "model = gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879ff7c",
   "metadata": {},
   "source": [
    "### Step 4.5: Generate the pos_neg_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59e4247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: 102000\n",
      "Wrote: pos_neg_pairs.json\n",
      "Example: {'negative': '193+198=? Sorry, I do not know!', 'positive': '193+198=? The answer is 391 because 193+198 equals 391.'}\n"
     ]
    }
   ],
   "source": [
    "# Generate >= 10k pos/neg pairs in same string style as the 4 examples provided\n",
    "# -> e.g. {\"negative\": \"79-7=? Sorry, I do not know!\",\t\"positive\": \"79-7=? The answer is 72 because 79-7 equals 72.\"}\n",
    "\n",
    "import json, random\n",
    "\n",
    "OUT_PATH = \"pos_neg_pairs.json\" # Overwrite pos_neg_pairs.json\n",
    "# TARGET = 11_000\n",
    "\n",
    "# This is for deterministic testing, comment out for truly random\n",
    "# SEED = 42 \n",
    "# random.seed(SEED)\n",
    "\n",
    "def pos_str(expr: str, ans: int | float, reason: str):\n",
    "    # \"79-7=? The answer is 52 because 79-7 equals 72.\"\n",
    "    if isinstance(ans, float) and abs(ans-round(ans)) < 1e-9:\n",
    "        ans = int(round(ans))\n",
    "    return f\"{expr} The answer is {ans} because {reason}.\"\n",
    "\n",
    "def neg_str(expr: str):\n",
    "    # \"79-7? Sorry, I do not know!\"\n",
    "    return f\"{expr} Sorry, I do not know!\"\n",
    "\n",
    "def make_add(a, b):\n",
    "    # Makes addition expression\n",
    "    expr = f\"{a}+{b}=?\"\n",
    "    ans = a + b\n",
    "    reason = f\"{a}+{b} equals {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "def make_sub(a, b):\n",
    "    # Make subtraction expressions\n",
    "    expr = f\"{a}-{b}=?\"\n",
    "    ans  = a - b\n",
    "    reason = f\"{a}-{b} equals {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "def make_mul(a, b):\n",
    "    # Make multiplication expressions (not provided in original example, created in similar form)\n",
    "    expr = f\"{a}*{b}=?\"\n",
    "    ans  = a * b\n",
    "    reason = f\"{a}*{b} equals {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "def make_div(a, b):\n",
    "    # Make division expressions (not provided in original example, created in similar form)\n",
    "    # Handle divide by zero (should not happen as randint(1, 19) should not generate divisor 0)\n",
    "    if b==0: return None        # add_batch at the bottom will skip this case\n",
    "    expr = f\"{a}/{b}=?\"\n",
    "    ans = round(a/b, 5)         # Round off answers to 5dp if >5dp\n",
    "    reason = f\"{a}/{b} equals {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "def make_solvex1(a, b):\n",
    "    # Make equations in the form of: x + a = b\n",
    "    expr = f\"x+{a}={b},x=?\"\n",
    "    ans = b - a\n",
    "    reason = f\"{b}-{a} equals to {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "def make_solvex2(a, b):\n",
    "    # Make equations in the form of: a * x = b\n",
    "    expr = f\"{a}*x={b},x=?\"\n",
    "    ans = round(b/a, 5)         # Round off answers to 5dp if >5dp\n",
    "    reason = f\"{b}/{a} equals to {ans}\"\n",
    "    return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "# Function to generate linear equations\n",
    "# def make_eq(a, b, x):\n",
    "#     # Make linear equations in the form of: c = a*x + b\n",
    "#     c = a*x + b\n",
    "#     expr = f\"{a}*x+{b}={c}, x=?\"\n",
    "#     ans  = x\n",
    "#     reason = f\"({c}-{b})/{a} equals {x}\"\n",
    "#     return {\"negative\": neg_str(expr), \"positive\": pos_str(expr, ans, reason)}\n",
    "\n",
    "# Accumulate records and prevent duplicate questions\n",
    "items, seen = [], set()\n",
    "\n",
    "# Funcation to generate a batch of type of equation pairs\n",
    "def add_batch(n, gen):\n",
    "    # Calls gen() until n unique records\n",
    "    made, tries = 0, 0\n",
    "    while made<n and tries<n*50: # Avoids infinite loops if gen() keeps returning None\n",
    "        tries +=1\n",
    "        rec = gen()             # Produces 1 pos_neg_pair in that particular equation type\n",
    "        if not rec:\n",
    "            continue\n",
    "        # De-duplicate by the question text\n",
    "        question = rec[\"positive\"].split(\" \", 1)[0]\n",
    "        if question in seen:\n",
    "            continue            # Skip failed or None cases (divide by 0)\n",
    "        seen.add(question)\n",
    "        items.append(rec)\n",
    "        made +=1\n",
    "\n",
    "# Coverage for testing with fixed seed, commented to generate truly random 100k pairs\n",
    "# add_batch(2, lambda: make_add(random.randint(1, 99), random.randint(1, 99)))      \n",
    "# add_batch(2, lambda: make_sub(random.randint(1, 99), random.randint(1, 99)))      \n",
    "# add_batch(2, lambda: make_mul(random.randint(10, 199), random.randint(1, 19)))     \n",
    "# add_batch(2, lambda: make_div(random.randint(10, 199), random.randint(1, 19)))     \n",
    "# add_batch(2, lambda: make_solvex1(random.randint(10, 199), random.randint(1, 199))) # Allows for negative values\n",
    "# add_batch(2, lambda: make_solvex2(random.randint(10, 199), random.randint(1, 19)))  # Same as make_div\n",
    "\n",
    "# If want to add linear equations\n",
    "#add_batch(2, lambda: make_eq(random.randint(2, 12), random.randint(-20, 20), random.randint(-20, 20)))\n",
    "\n",
    "# Coverage for 100k pairs, ~17_000 entries per equation type\n",
    "add_batch(17000, lambda: make_add(random.randint(1, 199), random.randint(1, 199)))        \n",
    "add_batch(17000, lambda: make_sub(random.randint(1, 199), random.randint(1, 199)))        \n",
    "add_batch(17000, lambda: make_mul(random.randint(1, 199), random.randint(1, 199)))     \n",
    "add_batch(17000, lambda: make_div(random.randint(1, 199), random.randint(1, 199)))      \n",
    "add_batch(17000, lambda: make_solvex1(random.randint(1, 199), random.randint(1, 199))) \n",
    "add_batch(17000, lambda: make_solvex2(random.randint(1, 199), random.randint(1, 199)))  \n",
    "\n",
    "# If want to add linear equations\n",
    "#add_batch(17000, lambda: make_eq(random.randint(2, 12), random.randint(-20, 20), random.randint(-20, 20)))\n",
    "\n",
    "print(\"Generated:\", len(items)) # Shows how many pairs\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(items, f, ensure_ascii=False, indent=2)\n",
    "print(\"Wrote:\", OUT_PATH)       # Shows which file overwritten\n",
    "print(\"Example:\", items[0])     # Print first pair as a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 102000\n",
      "Sample: {'negative': '193+198=? Sorry, I do not know!', 'positive': '193+198=? The answer is 391 because 193+198 equals 391.'}\n",
      "Type counts: {'add': 17000, 'sub': 17000, 'mul': 17000, 'div': 17000, 'solvex1': 17000, 'solvex2': 17000}\n",
      "File size ~MB: 14.377494\n"
     ]
    }
   ],
   "source": [
    "# Load data from ./data/pos_neg_pairs.json\n",
    "\n",
    "import json, re, collections, os, math\n",
    "PATH = \"pos_neg_pairs.json\"\n",
    "data = json.load(open(PATH, \"r\", encoding=\"utf-8\"))\n",
    "print(\"Total pairs:\", len(data))\n",
    "print(\"Sample:\", data[0])\n",
    "\n",
    "# Schema checks\n",
    "assert all((\"positive\" in r and \"negative\" in r) for r in data), \"Missing keys\"\n",
    "assert all(r[\"positive\"]!=r[\"negative\"] for r in data), \"Positive and negative are the same\"\n",
    "\n",
    "# Rough type distribution\n",
    "op_re = re.compile(r\"(\\+|-|\\*|/)|\\*x=|x\\+\")\n",
    "def kind(s):\n",
    "    s = s[\"positive\"]\n",
    "    if \"*x=\" in s: return \"solvex2\"\n",
    "    if \"x+\"  in s: return \"solvex1\"\n",
    "    m = op_re.search(s); \n",
    "    return {\"+\":\"add\",\"-\":\"sub\",\"*\":\"mul\",\"/\":\"div\"}.get(m.group(0)[0], \"other\") if m else \"other\"\n",
    "counts = collections.Counter(kind(r) for r in data)\n",
    "print(\"Type counts:\", dict(counts))\n",
    "\n",
    "print(\"File size ~MB:\", os.path.getsize(PATH)/1e6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 8,838,852\n",
      "LR: 0.0001 | wd: 0.01 | betas: (0.9, 0.95) | eps: 1e-8\n",
      "epochs: 5 | batch_size: 64 | accum: 1\n",
      "steps/epoch: 1594 | warmup_steps: 398 | total_steps: 7970\n",
      "DPO beta (for Step 7): 0.2\n"
     ]
    }
   ],
   "source": [
    "# recommend to use the AdamW optimizer \n",
    "\n",
    "# === Step 6: Optimizer (AdamW) + Scheduler (warmup  linear decay), using Step-2 config ===\n",
    "import math\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "assert 'model' in globals(), \"Model not found. Run Step 4 first.\"\n",
    "\n",
    "# Use Step-2 variables\n",
    "learning_rate    = base_lr        # from Step 2\n",
    "beta_dpo         = beta           # used in Step 7 loss\n",
    "epochs_to_train  = epochs         # from Step 2\n",
    "train_batch_size = batch_size     # from Step 2\n",
    "\n",
    "# If Step 5 defined `lines`, prefer it; else fall back to `data`\n",
    "num_train_pairs = len(globals().get('lines', globals().get('data', [])))\n",
    "assert num_train_pairs > 0, \"No training data found. Run Step 5 to load data.\"\n",
    "\n",
    "grad_accum_steps = 1       # keep simple/explicit for this lab\n",
    "warmup_ratio     = 0.05    # ~5% warmup\n",
    "\n",
    "# ---- AdamW param groups (no decay on biases/LayerNorm/embeddings wte/wpe) ----\n",
    "decay, no_decay = set(), set()\n",
    "for name, p in model.named_parameters():\n",
    "    if not p.requires_grad:\n",
    "        continue\n",
    "    n = name.lower()\n",
    "    if any(k in n for k in [\"bias\", \"layernorm\", \"ln\", \"norm\", \"emb\", \"embedding\", \"wte\", \"wpe\"]):\n",
    "        no_decay.add(name)\n",
    "    else:\n",
    "        decay.add(name)\n",
    "\n",
    "param_dict = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "optim_groups = [\n",
    "    {\"params\": [param_dict[n] for n in sorted(decay)],    \"weight_decay\": 0.01},\n",
    "    {\"params\": [param_dict[n] for n in sorted(no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8)\n",
    "\n",
    "# ---- Scheduler: step every optimizer step ----\n",
    "steps_per_epoch = max(1, math.ceil(num_train_pairs / max(1, train_batch_size * grad_accum_steps)))\n",
    "total_steps     = steps_per_epoch * max(1, epochs_to_train)\n",
    "warmup_steps    = max(1, int(warmup_ratio * total_steps))\n",
    "\n",
    "def _lr_lambda(step: int):\n",
    "    if step < warmup_steps:\n",
    "        return float(step) / float(warmup_steps)                    # linear warmup 01\n",
    "    progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "    return max(0.0, 1.0 - progress)                                 # linear decay 10\n",
    "\n",
    "scheduler = LambdaLR(optimizer, _lr_lambda)\n",
    "\n",
    "# ---- Summary (so you can confirm it pulled Step-2 values) ----\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {trainable_params:,}\")\n",
    "print(f\"LR: {learning_rate} | wd: 0.01 | betas: (0.9, 0.95) | eps: 1e-8\")\n",
    "print(f\"epochs: {epochs_to_train} | batch_size: {train_batch_size} | accum: {grad_accum_steps}\")\n",
    "print(f\"steps/epoch: {steps_per_epoch} | warmup_steps: {warmup_steps} | total_steps: {total_steps}\")\n",
    "print(f\"DPO beta (for Step 7): {beta_dpo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "868eca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with hard_negative: 40668 / 102000\n"
     ]
    }
   ],
   "source": [
    "# Add plausible-wrong answers to ~40% of items.\n",
    "import re, random, json\n",
    "\n",
    "def add_hard_negatives(dataset, frac=0.4):\n",
    "    out = []\n",
    "    for r in dataset:\n",
    "        r = dict(r)  # shallow copy\n",
    "        if random.random() < frac:\n",
    "            s = r[\"positive\"]\n",
    "            m = re.search(r\"The answer is ([\\-0-9\\.]+)\", s)\n",
    "            if m:\n",
    "                val = m.group(1)\n",
    "                try:\n",
    "                    if \".\" in val:\n",
    "                        wrong = f\"{float(val)+random.choice([-0.1, 0.1]):.2f}\"\n",
    "                    else:\n",
    "                        wrong = str(int(val)+random.choice([-1, 1]))\n",
    "                    r[\"hard_negative\"] = s.replace(f\"The answer is {val}\",\n",
    "                                                   f\"The answer is {wrong}\")\n",
    "                except:\n",
    "                    pass\n",
    "        out.append(r)\n",
    "    return out\n",
    "\n",
    "data_hn = add_hard_negatives(data, frac=0.4)\n",
    "print(\"with hard_negative:\", sum(\"hard_negative\" in r for r in data_hn), \"/\", len(data_hn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1593it [3:37:43,  8.20s/it, loss=0.0456, lr=0.00e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "486it [1:06:47,  8.25s/it, loss=0.0425, lr=0.00e+00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Optimser step\u001b[39;00m\n\u001b[32m     27\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     30\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\Y4S1\\SC3000\\Lab Assignment 1\\NanoGPT-Math\\venv\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\Y4S1\\SC3000\\Lab Assignment 1\\NanoGPT-Math\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\Y4S1\\SC3000\\Lab Assignment 1\\NanoGPT-Math\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "total_steps = len(data_hn) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    pbar = tqdm(get_batches(data, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "        model.train()\n",
    "\n",
    "        # Compute logprobs\n",
    "        neg_logprob = compute_logprob(neg_tensor)\n",
    "        pos_logprob = compute_logprob(pos_tensor)\n",
    "        \n",
    "        # DPO loss\n",
    "        pref = (pos_logprob - neg_logprob) / beta_dpo\n",
    "        loss = -F.logsigmoid(pref).mean()\n",
    "        loss = loss - pos_logprob.mean() * 0.1  # KL penalty term\n",
    "\n",
    "        # Optimser step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Progress bar update\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{scheduler.get_last_lr()[0]:.2e}\")\n",
    "            \n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09027262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 17+19=?\n",
      "Pred: 110   Gold: 36   \n",
      "\n",
      "Q: 3*17=?\n",
      "Pred: 104   Gold: 51   \n",
      "\n",
      "Q: 72/4=?\n",
      "Pred: 1.11444   Gold: 18.0   \n",
      "\n",
      "Q: 72-x=34,x=?\n",
      "Pred: -1   Gold: 38   \n",
      "\n",
      "Q: x*11=44,x=?\n",
      "Pred: -144   Gold:    \n",
      "\n",
      "Q: 3*17=?\n",
      "Pred: 104   Gold: 51   \n",
      "\n",
      "Q: 72/4=?\n",
      "Pred: 1.11444   Gold: 18.0   \n",
      "\n",
      "Q: 72-x=34,x=?\n",
      "Pred: -1   Gold: 38   \n",
      "\n",
      "Accuracy: 0/8 = 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).to(device)\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "\n",
    "# Greedy, constrained decoding: Extract first numeric span after \"The answer is\"\n",
    "DIGITS = set(\"0123456789-+.\")\n",
    "STOP_ID = 0\n",
    "CTX = max_length\n",
    "\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "# with torch.no_grad():\n",
    "#     for prompt in test_set: \n",
    "#         prompt_ids = encode(prompt)\n",
    "#         ###########################################################\n",
    "#         # Please complete the test code here!\n",
    "#         # ...\n",
    "#         # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "#         # ...\n",
    "#         ###########################################################\n",
    "\n",
    "#         # # Generate continuation and print\n",
    "#         # x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "#         # # For evaluation, we generate max_new_tokens tokens\n",
    "#         # out = gpt.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "\n",
    "#         # # Robustly get a 1D list[int] sequence from \"out\"\n",
    "#         # seq = out[0]\n",
    "#         # if isinstance(seq, torch.Tensor):\n",
    "#         #     seq = seq.squeeze().tolist()\n",
    "#         # if seq and isinstance(seq[0], (list, tuple)):\n",
    "#         #     seq = [tok for sub in seq for tok in sub]\n",
    "#         # txt = decode(seq)\n",
    "\n",
    "#         # # Show only newly generated part\n",
    "#         # gen_txt = txt[len(prompt):].split('\\n')[0].strip()\n",
    "#         # print(f\"Prompt: {prompt}\\nGenerated: {gen_txt}\\n\")\n",
    "\n",
    "#         seed = prompt + \" The answer is \"\n",
    "#         x = torch.tensor([[stoi.get(c, FALLBACK_ID) for c in seed]], dtype=torch.long, device=device)\n",
    "#         # greedy generate (argmax)\n",
    "#         for _ in range(max_new_tokens):\n",
    "#             logits, _ = gpt(x[:, -max_length:], full_seq=True)\n",
    "#             next_id = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
    "#             x = torch.cat([x, next_id], dim=1)\n",
    "#             if next_id.item() == 0:  # stop on pad/0\n",
    "#                 break\n",
    "#         seq = x[0].tolist()\n",
    "#         txt = decode(seq)\n",
    "#         gen_txt = txt[len(prompt):].split(\"\\n\", 1)[0].strip()\n",
    "#         print(f\"Prompt: {prompt}\\nGenerated: {gen_txt}\\n\")\n",
    "\n",
    "# Greedy function\n",
    "def greedy_answer(prompt: str, max_steps: int = 24) -> str:\n",
    "    seed = prompt + \" The answer is \"\n",
    "    x = torch.tensor([[stoi.get(c, FALLBACK_ID) for c in seed]], dtype=torch.long, device=device)\n",
    "    ans = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_steps):\n",
    "            logits, _ = gpt(x[:, -CTX:], full_seq=True)\n",
    "            next_id = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)  # GREEDY (no sampling)\n",
    "            x = torch.cat([x, next_id], dim=1)\n",
    "            t = int(next_id.item())\n",
    "            if t == STOP_ID:\n",
    "                break\n",
    "            ch = itos[t]\n",
    "            if ch in DIGITS:\n",
    "                ans.append(ch)         # start/continue capturing digits\n",
    "            elif ans:\n",
    "                break                  # stop when we leave the first digit span\n",
    "    return \"\".join(ans)\n",
    "\n",
    "# iny solver for your prompt formats (gold answers)\n",
    "import re\n",
    "def solve(prompt: str) -> str:\n",
    "    s = prompt.replace(\" \", \"\")\n",
    "    if re.match(r\"^\\d+\\+\\d+=\\?$\", s):\n",
    "        a,b = map(int, s[:-2].split(\"+\")); return str(a+b)\n",
    "    if re.match(r\"^\\d+-\\d+=\\?$\", s):\n",
    "        a,b = map(int, s[:-2].split(\"-\")); return str(a-b)\n",
    "    if re.match(r\"^\\d+\\*\\d+=\\?$\", s):\n",
    "        a,b = map(int, s[:-2].split(\"*\")); return str(a*b)\n",
    "    if re.match(r\"^\\d+/\\d+=\\?$\", s):\n",
    "        a,b = map(int, s[:-2].split(\"/\")); return str(a/b)\n",
    "    if re.match(r\"^x\\+\\d+=\\d+,x=\\?$\", s):\n",
    "        a,b = map(int, s[2:-4].split(\"=\")); return str(b-a)\n",
    "    if re.match(r\"^\\d+\\*x=\\d+,x=\\?$\", s):\n",
    "        a,b = map(int, s[:-4].split(\"*x=\")); return str(b/a)\n",
    "    if re.match(r\"^\\d+-x=\\d+,x=\\?$\", s):\n",
    "        a,b = map(int, s[:-4].split(\"-x=\")); return str(a-b)\n",
    "    return \"\"\n",
    "\n",
    "# Evaluate\n",
    "correct, total = 0, 0\n",
    "for q in test_set:\n",
    "    pred = greedy_answer(q, max_steps=24)\n",
    "    gold = solve(q)\n",
    "    # compare as floats (covers division); fallback to string equality\n",
    "    try:\n",
    "        ok = abs(float(pred) - float(gold)) < 1e-6\n",
    "    except:\n",
    "        ok = (pred == gold)\n",
    "    total += 1; correct += int(ok)\n",
    "    print(f\"Q: {q}\\nPred: {pred}   Gold: {gold}   {'' if ok else ''}\\n\")\n",
    "print(f\"Accuracy: {correct}/{total} = {correct/total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "151f457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives with 'The answer is': 102000 / 102000\n",
      "OOV chars: ['!']\n",
      "pos len median/95p/max: 61.0 72 74\n",
      "neg len median/95p/max: 35.0 39 39\n",
      "pos >64 tokens: 29929\n",
      "positives with '.' (likely decimals): 102000\n"
     ]
    }
   ],
   "source": [
    "import json, statistics, re\n",
    "data = json.load(open(\"pos_neg_pairs.json\",\"r\",encoding=\"utf-8\"))\n",
    "\n",
    "# 1) Schema + presence of key phrase\n",
    "assert all((\"positive\" in r and \"negative\" in r) for r in data)\n",
    "p_has_ans = sum(\" The answer is \" in r[\"positive\"] for r in data)\n",
    "print(\"positives with 'The answer is':\", p_has_ans, \"/\", len(data))\n",
    "\n",
    "# 2) OOV coverage vs your vocab\n",
    "bad = sorted({c for r in data for c in (r[\"positive\"]+r[\"negative\"]) if c not in stoi})\n",
    "print(\"OOV chars:\", bad)\n",
    "\n",
    "# 3) Length stats and truncation risk (max_length=64; you append 4 newlines)\n",
    "def toks(s): return len(encode(s + \"\\n\\n\\n\\n\"))\n",
    "pos_lens = [toks(r[\"positive\"]) for r in data]\n",
    "neg_lens = [toks(r[\"negative\"]) for r in data]\n",
    "print(\"pos len median/95p/max:\", statistics.median(pos_lens), sorted(pos_lens)[int(0.95*len(pos_lens))], max(pos_lens))\n",
    "print(\"neg len median/95p/max:\", statistics.median(neg_lens), sorted(neg_lens)[int(0.95*len(neg_lens))], max(neg_lens))\n",
    "print(\"pos >64 tokens:\", sum(l>64 for l in pos_lens))\n",
    "\n",
    "# 4) Are many answers floats with long tails (harder for char LM)?\n",
    "float_like = sum(\".\" in r[\"positive\"] for r in data)\n",
    "print(\"positives with '.' (likely decimals):\", float_like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8af4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
